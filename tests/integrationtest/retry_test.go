/*
 * Copyright Â© 2025 Broadcom Inc. and/or its subsidiaries. All Rights Reserved.
 * All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *   http://www.apache.org/licenses/LICENSE-2.0
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// @AI-Generated
// [Generated by Cursor claude-4-sonnet]

package integrationtest

import (
	"context"
	"testing"
	"time"

	"github.com/onsi/gomega"

	"github.com/vmware/load-balancer-and-ingress-services-for-kubernetes/internal/retry"
	"github.com/vmware/load-balancer-and-ingress-services-for-kubernetes/pkg/utils"
)

// TestDequeueFastRetry tests the fast retry mechanism
// Fast retry is triggered when REST operations fail and need immediate retry
func TestDequeueFastRetry(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	// Setup test for service LB
	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Create a test VS key
	vsKey := "admin/cluster--red-ns-testsvc"

	// Get the graph layer queue
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil())

	// Verify the retry function doesn't panic and completes successfully
	// The function publishes to the queue which is immediately processed by workers
	g.Expect(func() {
		retry.DequeueFastRetry(vsKey)
	}).NotTo(gomega.Panic(), "Fast retry should not panic")

	// Give time for the queue to process
	time.Sleep(200 * time.Millisecond)

	// Verify that the queue system is still operational after retry
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
	g.Expect(graphQueue.NumWorkers).To(gomega.BeNumerically(">", 0))
}

// TestDequeueSlowRetry tests the slow retry mechanism
// Slow retry is triggered when REST operations fail and need delayed retry
func TestDequeueSlowRetry(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Create a test VS key
	vsKey := "admin/cluster--red-ns-testsvc"

	// Get the graph layer queue
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil())

	// Verify the retry function doesn't panic and completes successfully
	g.Expect(func() {
		retry.DequeueSlowRetry(vsKey)
	}).NotTo(gomega.Panic(), "Slow retry should not panic")

	// Give time for the queue to process
	time.Sleep(200 * time.Millisecond)

	// Verify that the queue system is still operational after retry
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
	g.Expect(graphQueue.NumWorkers).To(gomega.BeNumerically(">", 0))
}

// TestRetryWithMultipleKeys tests retry with multiple VS keys
func TestRetryWithMultipleKeys(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Create multiple test VS keys
	vsKeys := []string{
		"admin/cluster--red-ns-testsvc",
		"admin/cluster--red-ns-testsvc-2",
		"admin/cluster--red-ns-testsvc-3",
	}

	// Get the graph layer queue
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil())

	// Trigger fast retry for multiple keys - should not panic
	g.Expect(func() {
		for _, vsKey := range vsKeys {
			retry.DequeueFastRetry(vsKey)
		}
	}).NotTo(gomega.Panic(), "Multiple retry calls should not panic")

	// Wait for keys to be processed
	time.Sleep(300 * time.Millisecond)

	// Verify queue system is still operational
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
}

// TestRetryWithDifferentKeyFormats tests retry with various key formats
func TestRetryWithDifferentKeyFormats(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Test with different key formats
	testCases := []struct {
		name  string
		vsKey string
	}{
		{
			name:  "Standard VS key",
			vsKey: "admin/cluster--red-ns-testsvc",
		},
		{
			name:  "VS key with namespace",
			vsKey: "admin/cluster--red-ns-testsvc-2",
		},
		{
			name:  "VS key with special characters",
			vsKey: "admin/cluster--test-vs-with-dashes",
		},
		{
			name:  "Simple key",
			vsKey: "test-key",
		},
	}

	for _, tc := range testCases {
		t.Run(tc.name, func(t *testing.T) {
			g := gomega.NewGomegaWithT(t)

			// Get the graph layer queue
			graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
			g.Expect(graphQueue).NotTo(gomega.BeNil())

			// Trigger fast retry - should not panic with any key format
			g.Expect(func() {
				retry.DequeueFastRetry(tc.vsKey)
			}).NotTo(gomega.Panic(), "Retry should work with key format: %s", tc.vsKey)

			// Wait for processing
			time.Sleep(100 * time.Millisecond)
		})
	}
}

// TestRetryConcurrency tests concurrent retry calls
func TestRetryConcurrency(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Get the graph layer queue
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil())

	// Trigger concurrent retries
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	numConcurrent := 10
	done := make(chan bool, numConcurrent)
	panicked := make(chan interface{}, numConcurrent)

	for i := 0; i < numConcurrent; i++ {
		go func(idx int) {
			defer func() {
				if r := recover(); r != nil {
					panicked <- r
				}
			}()
			vsKey := "admin/cluster--concurrent-test-" + string(rune('0'+idx))
			retry.DequeueFastRetry(vsKey)
			done <- true
		}(i)
	}

	// Wait for all goroutines to complete or timeout
	completed := 0
	for completed < numConcurrent {
		select {
		case <-done:
			completed++
		case panicVal := <-panicked:
			t.Fatalf("Concurrent retry panicked: %v", panicVal)
		case <-ctx.Done():
			t.Fatal("Timeout waiting for concurrent retries")
		}
	}

	// Wait for keys to be processed
	time.Sleep(300 * time.Millisecond)

	// Verify queue system is still operational after concurrent operations
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
	g.Expect(graphQueue.NumWorkers).To(gomega.BeNumerically(">", 0))
}

// TestFastAndSlowRetryInteraction tests interaction between fast and slow retry
func TestFastAndSlowRetryInteraction(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	vsKey := "admin/cluster--red-ns-testsvc"

	// Get the graph layer queue
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil())

	// Trigger both fast and slow retry for the same key - should not panic
	g.Expect(func() {
		retry.DequeueFastRetry(vsKey)
		time.Sleep(50 * time.Millisecond)
		retry.DequeueSlowRetry(vsKey)
	}).NotTo(gomega.Panic(), "Both fast and slow retry should work for the same key")

	// Wait for keys to be processed
	time.Sleep(300 * time.Millisecond)

	// Verify queue system is still operational
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
}

// TestRetryAfterRESTFailure simulates a REST failure scenario and verifies retry
func TestRetryAfterRESTFailure(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Simulate a REST operation failure scenario
	// In real scenario, this would be triggered by a failed REST call
	vsKey := "admin/cluster--rest-failure-test"

	// Get the graph layer queue
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil())

	// Simulate REST failure by triggering retry - should not panic
	g.Expect(func() {
		retry.DequeueFastRetry(vsKey)
	}).NotTo(gomega.Panic(), "Retry after REST failure should not panic")

	// Wait for retry to be processed
	time.Sleep(200 * time.Millisecond)

	// Verify queue system is still operational
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
	g.Expect(graphQueue.NumWorkers).To(gomega.BeNumerically(">", 0))
}

// TestRetryQueueIntegration verifies that retry integrates properly with the queue system
func TestRetryQueueIntegration(t *testing.T) {
	g := gomega.NewGomegaWithT(t)

	SetUpTestForSvcLB(t, SINGLEPORTSVC)
	defer TearDownTestForSvcLB(t, g, SINGLEPORTSVC)

	// Verify graph layer queue exists
	graphQueue := utils.SharedWorkQueue().GetQueueByName(utils.GraphLayer)
	g.Expect(graphQueue).NotTo(gomega.BeNil(), "Graph layer queue should exist")
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer), "Queue name should be GraphLayer")

	// Verify queue has workers
	g.Expect(graphQueue.NumWorkers).To(gomega.BeNumerically(">", 0), "Queue should have workers")

	// Verify workqueue array is initialized
	g.Expect(len(graphQueue.Workqueue)).To(gomega.Equal(int(graphQueue.NumWorkers)),
		"Workqueue array should match number of workers")

	// Test retry integration - should not panic
	vsKey := "admin/cluster--integration-test"
	g.Expect(func() {
		retry.DequeueFastRetry(vsKey)
	}).NotTo(gomega.Panic(), "Retry should integrate with queue system without panicking")

	// Wait for processing
	time.Sleep(200 * time.Millisecond)

	// Verify queue system remains operational
	g.Expect(graphQueue.WorkqueueName).To(gomega.Equal(utils.GraphLayer))
	g.Expect(graphQueue.NumWorkers).To(gomega.BeNumerically(">", 0))
}
